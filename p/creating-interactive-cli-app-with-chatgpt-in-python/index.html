<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Bring the interaction with ChatGPT into your terminal and learn how to create powerful interactive CLI applications in Python."><title>Creating a Powerful Interactive CLI App with ChatGPT in Python</title><link rel=canonical href=https://python.study/p/creating-interactive-cli-app-with-chatgpt-in-python/><link rel=stylesheet href=/scss/style.min.1594ac3e17fd0bdba91fff49adf83d23c424563c68a6b2dc7b30569a15c87161.css><meta property="og:title" content="Creating a Powerful Interactive CLI App with ChatGPT in Python"><meta property="og:description" content="Bring the interaction with ChatGPT into your terminal and learn how to create powerful interactive CLI applications in Python."><meta property="og:url" content="https://python.study/p/creating-interactive-cli-app-with-chatgpt-in-python/"><meta property="og:site_name" content="Python Study"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="openai"><meta property="article:tag" content="prompt_toolkit"><meta property="article:published_time" content="2023-09-28T00:00:00+00:00"><meta property="article:modified_time" content="2023-09-28T00:00:00+00:00"><meta property="og:image" content="https://python.study/p/creating-interactive-cli-app-with-chatgpt-in-python/cover.jpeg"><meta name=twitter:title content="Creating a Powerful Interactive CLI App with ChatGPT in Python"><meta name=twitter:description content="Bring the interaction with ChatGPT into your terminal and learn how to create powerful interactive CLI applications in Python."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://python.study/p/creating-interactive-cli-app-with-chatgpt-in-python/cover.jpeg"><link rel="shortcut icon" href=/favicon.png><script async src="https://www.googletagmanager.com/gtag/js?id=G-RTW8ER847W"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-RTW8ER847W",{anonymize_ip:!1})}</script><style>:root{--code-font-family:"Source Code Pro", Menlo, Monaco, Consolas, "Courier New", monospace}</style><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@400;500&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/python-logo_hu59f4995e8b59f3a82a1e6b1c1b24787b_150090_300x0_resize_box_3.png width=300 height=299 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Python Study</a></h1><h2 class=site-description>Study Python in-depth through concise and interesting posts.</h2></div></header><ol class=social-menu><li><a href=https://github.com/amerkurev/python-study target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://www.linkedin.com/in/amerkurev target=_blank title=LinkedIn rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-linkedin" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 2a2 2 0 012-2h12a2 2 0 012 2v12a2 2 0 01-2 2H6a2 2 0 01-2-2z"/><path d="M8 11v5"/><path d="M8 8v.01"/><path d="M12 16v-5"/><path d="M16 16v-3a2 2 0 00-4 0"/></svg></a></li><li><a href=https://medium.com/@apps.merkurev target=_blank title=Medium rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-medium" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 2a2 2 0 012-2h12a2 2 0 012 2v12a2 2 0 01-2 2H6a2 2 0 01-2-2z"/><path d="M8 9h1l3 3 3-3h1"/><path d="M8 15h2"/><path d="M14 15h2"/><path d="M9 9v6"/><path d="M15 9v6"/></svg></a></li><li><a href=https://python.study/index.xml target=_blank title=RSS rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="5" cy="19" r="1"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg></a></li><li><a href=https://t.me/pystudy target=_blank title=Telegram rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-telegram" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M15 10l-4 4 6 6 4-16-18 7 4 2 2 6 3-4"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li><a href=/writing/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-writing" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M20 17V5c0-1.121-.879-2-2-2s-2 .879-2 2v12l2 2 2-2z"/><path d="M16 7h4"/><path d="M18 19H5a2 2 0 110-4h4a2 2 0 100-4H6"/></svg><span>Write a post</span></a></li><li><a href=/subscribe/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user-plus" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M8 7a4 4 0 108 0A4 4 0 008 7"/><path d="M16 19h6"/><path d="M19 16v6"/><path d="M6 21v-2a4 4 0 014-4h4"/></svg><span>Subscribe to us</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/creating-interactive-cli-app-with-chatgpt-in-python/><img src=/p/creating-interactive-cli-app-with-chatgpt-in-python/cover_hu02aa61ae1d9de35cbe238d2676170cb9_92491_800x0_resize_q75_box.jpeg srcset="/p/creating-interactive-cli-app-with-chatgpt-in-python/cover_hu02aa61ae1d9de35cbe238d2676170cb9_92491_800x0_resize_q75_box.jpeg 800w, /p/creating-interactive-cli-app-with-chatgpt-in-python/cover_hu02aa61ae1d9de35cbe238d2676170cb9_92491_1600x0_resize_q75_box.jpeg 1600w" width=800 height=365 loading=lazy alt="Featured image of post Creating a Powerful Interactive CLI App with ChatGPT in Python"></a></div><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/p/creating-interactive-cli-app-with-chatgpt-in-python/>Creating a Powerful Interactive CLI App with ChatGPT in Python</a></h2><h3 class=article-subtitle>Bring the interaction with ChatGPT into your terminal and learn how to create powerful interactive CLI applications in Python.</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Sep 28, 2023</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>8 minute read</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg><a href=/tags/openai/>openai</a>
<a href=/tags/prompt_toolkit/>prompt_toolkit</a></div></footer></div></header><section class=article-content><p>As developers, we spend a significant amount of time in our terminal.
It&rsquo;s only logical to bring the interaction with ChatGPT into our terminal.
Plus, it&rsquo;s a great opportunity to learn how to create powerful interactive CLI applications in Python.
Forget about the standard <code>input()</code>, we are going to make it much cooler!</p><p>To get started, we need to interact with ChatGPT via API, so we need an API Key (<code>OPENAI_API_KEY</code>).
You can read more about how to get access to the ChatGPT API in the <a class=link href=https://help.openai.com/en/collections/3675931-openai-api target=_blank rel=noopener>official documentation</a>.
We also need two external Python libraries: <a class=link href=https://python-prompt-toolkit.readthedocs.io/ target=_blank rel=noopener>Python Prompt Toolkit 3.0</a> and <a class=link href="https://platform.openai.com/docs/api-reference/introduction?lang=python" target=_blank rel=noopener>OpenAI Python Library</a>.
Install them in your environment to make sure all the examples below work for you.</p><h3 id=v1-openai-api>v1. openai api</h3><p>Let&rsquo;s start with a very simple and naive version of our CLI application:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>  <span class=c1># pip install &#34;openai&gt;=1.7.0&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Please remember to export your API key to environment variables.</span>
</span></span><span class=line><span class=cl><span class=c1># $&gt; export OPENAI_API_KEY=...</span>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s1>&#39;OPENAI_API_KEY&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>openai_model</span> <span class=o>=</span> <span class=s1>&#39;gpt-3.5-turbo&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>messages</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=c1># system message first, it helps set the behavior of the assistant</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;system&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=s1>&#39;You are a helpful assistant.&#39;</span><span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>message</span> <span class=o>=</span> <span class=nb>input</span><span class=p>(</span><span class=s1>&#39;Human: &#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>message</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;user&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>message</span><span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=c1># https://platform.openai.com/docs/guides/chat/chat-vs-completions</span>
</span></span><span class=line><span class=cl>        <span class=n>chat_completion</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>=</span><span class=n>openai_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>messages</span><span class=o>=</span><span class=n>messages</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=c1># Temperature: 0.5 to 0.7 for a balance</span>
</span></span><span class=line><span class=cl>            <span class=c1># between creativity and coherence.</span>
</span></span><span class=line><span class=cl>            <span class=n>temperature</span><span class=o>=</span><span class=mf>.5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>content</span> <span class=o>=</span> <span class=n>chat_completion</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Robot: </span><span class=si>{</span><span class=n>content</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;assistant&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>content</span><span class=p>})</span>
</span></span></code></pre></div><p>This code is straightforward and works!
You can run it and communicate with ChatGPT.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>Human: Hello, how are you doing, robot?
</span></span><span class=line><span class=cl>Robot: Hello! I&#39;m doing well, thank you for asking. As an AI assistant, I don&#39;t have feelings, but I&#39;m here to help you with any questions or tasks you have. How can I assist you today?
</span></span></code></pre></div><p>However, if you use this script daily, it will soon become annoying.
Why? Because it&rsquo;s terribly inconvenient.
You can&rsquo;t move the cursor, delete something from the middle of a sentence, you don&rsquo;t have multiline input, no history of your input, no &ldquo;clean&rdquo; exit from the dialog (Ctrl+C leads to an unhandled <code>KeyboardInterrupt</code> exception), etc.</p><p>But all these issues can be easily fixed with the powerful and popular <a class=link href=https://github.com/prompt-toolkit/python-prompt-toolkit/ target=_blank rel=noopener>prompt_toolkit</a> library.
Let&rsquo;s gradually improve our first version of the program.</p><h3 id=v2-prompt_toolkit>v2. prompt_toolkit</h3><p>By simply replacing the standard Python <code>input</code> with the <code>prompt</code> from the <code>prompt_toolkit</code> library, we gain the ability to move the cursor and correct something in the middle or at the beginning of a sentence, i.e., edit our prompt in a very familiar manner.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>  <span class=c1># pip install &#34;openai&gt;=1.7.0&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit</span> <span class=kn>import</span> <span class=n>prompt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s1>&#39;OPENAI_API_KEY&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>openai_model</span> <span class=o>=</span> <span class=s1>&#39;gpt-3.5-turbo&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>messages</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;system&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=s1>&#39;You are a helpful assistant.&#39;</span><span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>message</span> <span class=o>=</span> <span class=n>prompt</span><span class=p>(</span><span class=s1>&#39;Human: &#39;</span><span class=p>)</span>  <span class=c1># only one change</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>message</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;user&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>message</span><span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=n>chat_completion</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>=</span><span class=n>openai_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>messages</span><span class=o>=</span><span class=n>messages</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>temperature</span><span class=o>=</span><span class=mf>.5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>content</span> <span class=o>=</span> <span class=n>chat_completion</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Robot: </span><span class=si>{</span><span class=n>content</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;assistant&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>content</span><span class=p>})</span>
</span></span></code></pre></div><p>This is already a good result, but it&rsquo;s just the beginning.</p><h3 id=v3-multiline-input>v3. multiline input</h3><p>The <code>prompt</code> function accepts several dozen different parameters that add various cool features for input in our program.
Let&rsquo;s activate some parameters of the <code>prompt</code> function to add a bit of color to our application, change the cursor view, and&mldr; add a multiline input mode!</p><p>Sometimes our request to ChatGPT may contain not one, but many lines.
Therefore, multiline input will be very convenient.
However, keep in mind that the <code>Enter</code> key will now insert a newline instead of accepting and returning the input.
The user will now have to press <code>Meta+Enter</code> to accept the input.
Or <code>Escape</code> followed by <code>Enter</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>  <span class=c1># pip install &#34;openai&gt;=1.7.0&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit</span> <span class=kn>import</span> <span class=n>prompt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit.cursor_shapes</span> <span class=kn>import</span> <span class=n>CursorShape</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit</span> <span class=kn>import</span> <span class=n>print_formatted_text</span><span class=p>,</span> <span class=n>HTML</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s1>&#39;OPENAI_API_KEY&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>openai_model</span> <span class=o>=</span> <span class=s1>&#39;gpt-3.5-turbo&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>messages</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;system&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=s1>&#39;You are a helpful assistant.&#39;</span><span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>reply_template</span> <span class=o>=</span> <span class=s1>&#39;&lt;style fg=&#34;ansiwhite&#34; bg=&#34;ansigreen&#34;&gt; Robot:&lt;/style&gt; </span><span class=si>%s</span><span class=s1>&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_prompt</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s1>&#39;bg:cornsilk fg:maroon&#39;</span><span class=p>,</span> <span class=s1>&#39; Human:&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>message</span> <span class=o>=</span> <span class=n>prompt</span><span class=p>(</span><span class=n>get_prompt</span><span class=p>,</span> <span class=n>cursor</span><span class=o>=</span><span class=n>CursorShape</span><span class=o>.</span><span class=n>BLOCK</span><span class=p>,</span> <span class=n>multiline</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>message</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;user&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>message</span><span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=n>chat_completion</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>=</span><span class=n>openai_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>messages</span><span class=o>=</span><span class=n>messages</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>temperature</span><span class=o>=</span><span class=mf>.5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>content</span> <span class=o>=</span> <span class=n>chat_completion</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>        <span class=n>print_formatted_text</span><span class=p>(</span><span class=n>HTML</span><span class=p>(</span><span class=n>reply_template</span> <span class=o>%</span> <span class=n>content</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;assistant&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>content</span><span class=p>})</span>
</span></span></code></pre></div><p>Let&rsquo;s test the multiline input mode with an example.
Let&rsquo;s ask ChatGPT a multiline question:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>Human: Hello, Robot! Can you fix the code example below?
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>       print(&#39;multiline mode&#34;)  # it&#39;s Python
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Robot: Certainly! It looks like there&#39;s a small error in the code. The closing quotation mark for the string is incorrect. Here&#39;s the corrected code:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>       print(&#39;multiline mode&#39;)  # it&#39;s Python
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>       Now the code should work properly and print &#39;multiline mode&#39;.
</span></span></code></pre></div><h3 id=v4-history>v4. history</h3><p>We&rsquo;re used to our shell &ldquo;remembering&rdquo; the history of our commands, which can be stored in <code>.bash_history</code> file, for example.
Also, our shells can make suggestions, which can be predefined or taken from our command history.
We could also use this functionality when communicating with ChatGPT in the terminal.
Plus, it&rsquo;s not difficult to enable these features in <code>prompt_toolkit</code>.</p><p>In the example below, we&rsquo;ll already have a history of our requests to ChatGPT.
And this history will be stored between runs of our application in the <code>.prompt_history</code> file.</p><p>Based on this history, suggestions will be formed, which can be activated by pressing the &ldquo;right arrow&rdquo; key (➡️).</p><p>Another difference from previous versions: the <code>PromptSession</code> class will be used.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>  <span class=c1># pip install &#34;openai&gt;=1.7.0&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit</span> <span class=kn>import</span> <span class=n>PromptSession</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit.history</span> <span class=kn>import</span> <span class=n>FileHistory</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit.auto_suggest</span> <span class=kn>import</span> <span class=n>AutoSuggestFromHistory</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit.cursor_shapes</span> <span class=kn>import</span> <span class=n>CursorShape</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit</span> <span class=kn>import</span> <span class=n>print_formatted_text</span><span class=p>,</span> <span class=n>HTML</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s1>&#39;OPENAI_API_KEY&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>openai_model</span> <span class=o>=</span> <span class=s1>&#39;gpt-3.5-turbo&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>messages</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;system&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=s1>&#39;You are a helpful assistant.&#39;</span><span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>reply_template</span> <span class=o>=</span> <span class=s1>&#39;&lt;style fg=&#34;ansiwhite&#34; bg=&#34;ansigreen&#34;&gt; Robot:&lt;/style&gt; </span><span class=si>%s</span><span class=s1>&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_prompt</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s1>&#39;bg:cornsilk fg:maroon&#39;</span><span class=p>,</span> <span class=s1>&#39; Human:&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>prompt_history</span> <span class=o>=</span> <span class=n>FileHistory</span><span class=p>(</span><span class=s1>&#39;.prompt_history&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>session</span> <span class=o>=</span> <span class=n>PromptSession</span><span class=p>(</span><span class=n>history</span><span class=o>=</span><span class=n>prompt_history</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>message</span> <span class=o>=</span> <span class=n>session</span><span class=o>.</span><span class=n>prompt</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>get_prompt</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>cursor</span><span class=o>=</span><span class=n>CursorShape</span><span class=o>.</span><span class=n>BLOCK</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>auto_suggest</span><span class=o>=</span><span class=n>AutoSuggestFromHistory</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=n>multiline</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>message</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;user&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>message</span><span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=n>chat_completion</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>=</span><span class=n>openai_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>messages</span><span class=o>=</span><span class=n>messages</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>temperature</span><span class=o>=</span><span class=mf>.5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>content</span> <span class=o>=</span> <span class=n>chat_completion</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>        <span class=n>print_formatted_text</span><span class=p>(</span><span class=n>HTML</span><span class=p>(</span><span class=n>reply_template</span> <span class=o>%</span> <span class=n>content</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;assistant&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>content</span><span class=p>})</span>
</span></span></code></pre></div><p>Test this version of the script: it&rsquo;s not much larger than the first one, but it makes the user&rsquo;s input much more convenient.</p><h3 id=v5-dialog>v5. dialog</h3><p>In our program, there&rsquo;s a very important global setting - the ChatGPT model we use (<code>openai_model</code>).
It would be convenient to choose a specific ChatGPT model at the time of script launch.
Let&rsquo;s implement this feature by adding a full-screen dialog to select the ChatGPT model.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>  <span class=c1># pip install &#34;openai&gt;=1.7.0&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit</span> <span class=kn>import</span> <span class=n>PromptSession</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit.history</span> <span class=kn>import</span> <span class=n>FileHistory</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit.auto_suggest</span> <span class=kn>import</span> <span class=n>AutoSuggestFromHistory</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit.cursor_shapes</span> <span class=kn>import</span> <span class=n>CursorShape</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit</span> <span class=kn>import</span> <span class=n>print_formatted_text</span><span class=p>,</span> <span class=n>HTML</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit.shortcuts</span> <span class=kn>import</span> <span class=n>radiolist_dialog</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s1>&#39;OPENAI_API_KEY&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>openai_model</span> <span class=o>=</span> <span class=s1>&#39;gpt-3.5-turbo&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>messages</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;system&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=s1>&#39;You are a helpful assistant.&#39;</span><span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>reply_template</span> <span class=o>=</span> <span class=s1>&#39;&lt;style fg=&#34;ansiwhite&#34; bg=&#34;ansigreen&#34;&gt; Robot:&lt;/style&gt; </span><span class=si>%s</span><span class=s1>&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_prompt</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s1>&#39;bg:cornsilk fg:maroon&#39;</span><span class=p>,</span> <span class=s1>&#39; Human:&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>prompt_history</span> <span class=o>=</span> <span class=n>FileHistory</span><span class=p>(</span><span class=s1>&#39;.prompt_history&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>session</span> <span class=o>=</span> <span class=n>PromptSession</span><span class=p>(</span><span class=n>history</span><span class=o>=</span><span class=n>prompt_history</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>openai_model</span> <span class=o>=</span> <span class=n>radiolist_dialog</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>title</span><span class=o>=</span><span class=s1>&#39;Choosing a ChatGPT model&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span><span class=o>=</span><span class=s1>&#39;Which ChatGPT model would you like ?&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>values</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s1>&#39;gpt-3.5-turbo&#39;</span><span class=p>,</span> <span class=s1>&#39;gpt-3.5-turbo&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s1>&#39;gpt-3.5-turbo-16k&#39;</span><span class=p>,</span> <span class=s1>&#39;gpt-3.5-turbo-16k&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s1>&#39;gpt-4&#39;</span><span class=p>,</span> <span class=s1>&#39;gpt-4&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s1>&#39;gpt-4-1106-preview&#39;</span><span class=p>,</span> <span class=s1>&#39;gpt-4-1106-preview (turbo)&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>)</span><span class=o>.</span><span class=n>run</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>while</span> <span class=n>openai_model</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>message</span> <span class=o>=</span> <span class=n>session</span><span class=o>.</span><span class=n>prompt</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>get_prompt</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>cursor</span><span class=o>=</span><span class=n>CursorShape</span><span class=o>.</span><span class=n>BLOCK</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>auto_suggest</span><span class=o>=</span><span class=n>AutoSuggestFromHistory</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=n>multiline</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>message</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;user&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>message</span><span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=n>chat_completion</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>=</span><span class=n>openai_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>messages</span><span class=o>=</span><span class=n>messages</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>temperature</span><span class=o>=</span><span class=mf>.5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>content</span> <span class=o>=</span> <span class=n>chat_completion</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>        <span class=n>print_formatted_text</span><span class=p>(</span><span class=n>HTML</span><span class=p>(</span><span class=n>reply_template</span> <span class=o>%</span> <span class=n>content</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;assistant&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>content</span><span class=p>})</span>
</span></span></code></pre></div><p>Running this version of the script, you&rsquo;ll see something like this:</p><p><img src=/p/creating-interactive-cli-app-with-chatgpt-in-python/cover.jpeg width=1690 height=772 srcset="/p/creating-interactive-cli-app-with-chatgpt-in-python/cover_hu02aa61ae1d9de35cbe238d2676170cb9_92491_480x0_resize_q75_box.jpeg 480w, /p/creating-interactive-cli-app-with-chatgpt-in-python/cover_hu02aa61ae1d9de35cbe238d2676170cb9_92491_1024x0_resize_q75_box.jpeg 1024w" loading=lazy alt="radio list dialog" class=gallery-image data-flex-grow=218 data-flex-basis=525px></p><h3 id=v6-graceful-stop>v6. graceful stop</h3><p>It&rsquo;s time to add a graceful stop to our program, for example, exit by Ctrl+C.
Also, let&rsquo;s rewrite our entire script in an asynchronous style.
This version of the script can already be used on a daily basis without any discomfort 😊</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>asyncio</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>AsyncOpenAI</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit</span> <span class=kn>import</span> <span class=n>PromptSession</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit.history</span> <span class=kn>import</span> <span class=n>FileHistory</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit.auto_suggest</span> <span class=kn>import</span> <span class=n>AutoSuggestFromHistory</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit.cursor_shapes</span> <span class=kn>import</span> <span class=n>CursorShape</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit</span> <span class=kn>import</span> <span class=n>print_formatted_text</span><span class=p>,</span> <span class=n>HTML</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit.shortcuts</span> <span class=kn>import</span> <span class=n>radiolist_dialog</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prompt_toolkit.patch_stdout</span> <span class=kn>import</span> <span class=n>patch_stdout</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>aclient</span> <span class=o>=</span> <span class=n>AsyncOpenAI</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s1>&#39;OPENAI_API_KEY&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_prompt</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s1>&#39;bg:cornsilk fg:maroon&#39;</span><span class=p>,</span> <span class=s1>&#39; Human:&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>choose_openai_model</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>radiolist_dialog</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>title</span><span class=o>=</span><span class=s1>&#39;Choosing a ChatGPT model&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>text</span><span class=o>=</span><span class=s1>&#39;Which ChatGPT model would you like ?&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>values</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=s1>&#39;gpt-3.5-turbo&#39;</span><span class=p>,</span> <span class=s1>&#39;gpt-3.5-turbo&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=s1>&#39;gpt-3.5-turbo-16k&#39;</span><span class=p>,</span> <span class=s1>&#39;gpt-3.5-turbo-16k&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=s1>&#39;gpt-4&#39;</span><span class=p>,</span> <span class=s1>&#39;gpt-4&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=s1>&#39;gpt-4-1106-preview&#39;</span><span class=p>,</span> <span class=s1>&#39;gpt-4-1106-preview (turbo)&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span><span class=o>.</span><span class=n>run</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>main</span><span class=p>(</span><span class=n>openai_model</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>messages</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;system&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=s1>&#39;You are a helpful assistant.&#39;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>name</span> <span class=o>=</span> <span class=n>HTML</span><span class=p>(</span><span class=s1>&#39;&lt;style fg=&#34;ansiwhite&#34; bg=&#34;ansigreen&#34;&gt; Robot:&lt;/style&gt; &#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>prompt_history</span> <span class=o>=</span> <span class=n>FileHistory</span><span class=p>(</span><span class=s1>&#39;.prompt_history&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>session</span> <span class=o>=</span> <span class=n>PromptSession</span><span class=p>(</span><span class=n>history</span><span class=o>=</span><span class=n>prompt_history</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>patch_stdout</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>message</span> <span class=o>=</span> <span class=k>await</span> <span class=n>session</span><span class=o>.</span><span class=n>prompt_async</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>get_prompt</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>cursor</span><span class=o>=</span><span class=n>CursorShape</span><span class=o>.</span><span class=n>BLOCK</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>auto_suggest</span><span class=o>=</span><span class=n>AutoSuggestFromHistory</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                <span class=n>multiline</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>message</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;user&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>message</span><span class=p>})</span>
</span></span><span class=line><span class=cl>                <span class=n>print_formatted_text</span><span class=p>(</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>chat_completion</span> <span class=o>=</span> <span class=k>await</span> <span class=n>aclient</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>model</span><span class=o>=</span><span class=n>openai_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>messages</span><span class=o>=</span><span class=n>messages</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>temperature</span><span class=o>=</span><span class=mf>.5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>stream</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>  <span class=c1># the streaming mode</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=n>reply</span> <span class=o>=</span> <span class=s1>&#39;&#39;</span>
</span></span><span class=line><span class=cl>                <span class=k>async</span> <span class=k>for</span> <span class=n>chunk</span> <span class=ow>in</span> <span class=n>chat_completion</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>content</span> <span class=o>=</span> <span class=n>chunk</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>delta</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>                    <span class=n>print_formatted_text</span><span class=p>(</span><span class=n>content</span><span class=p>,</span> <span class=n>end</span><span class=o>=</span><span class=s1>&#39;&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>reply</span> <span class=o>+=</span> <span class=n>content</span> <span class=ow>or</span> <span class=s1>&#39;&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=n>print_formatted_text</span><span class=p>(</span><span class=s1>&#39;&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;assistant&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>reply</span><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span> <span class=o>=</span> <span class=n>choose_openai_model</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>model</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>(</span><span class=n>model</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>KeyboardInterrupt</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>print_formatted_text</span><span class=p>(</span><span class=s1>&#39;GoodBye!&#39;</span><span class=p>)</span>
</span></span></code></pre></div><p>Now, running the script, you can press Ctrl+C at any time, and the program execution will be terminated.
At the same time, you won&rsquo;t see any unpleasant messages about unhandled exceptions.
The program ends correctly.</p><p>Moreover, the streaming mode for receiving a response from ChatGPT has been enabled.
In other words, once a part of the response from ChatGPT is received, it is immediately displayed on the screen.
In this form, waiting for a response from ChatGPT is a bit more fun, especially in those cases where the response from ChatGPT is really large and takes several seconds to fully form.</p><h3 id=v7->v7. &mldr;</h3><p>You can continue to develop our CLI application further.
For this, the <code>prompt_toolkit</code> package has a lot more interesting things.
But the examples provided are enough for the article.
Explore and use the rest on your own!</p></section><footer class=article-footer><br><div><a target=_blank href=https://github.com/amerkurev/python-study/issues/new><small>Please report any mistakes and shortcomings by opening an issue on GitHub.</small></a></div></footer></article><div class="article-list--compact links"><article><a href=https://github.com/amerkurev target=_blank rel=noopener><div class=article-details><h2 class=article-title>Posted by amerkurev</h2><footer class=article-time>https://github.com/amerkurev</footer></div><div class=article-image><img src="https://avatars.githubusercontent.com/u/28217522?v=4" loading=lazy></div></a></article></div><footer class=site-footer><section class=copyright>&copy;
2023 -
2024 Python Study</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.16.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>