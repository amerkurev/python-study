[{"content":"As developers, we spend a significant amount of time in our terminal. It\u0026rsquo;s only logical to bring the interaction with ChatGPT into our terminal. Plus, it\u0026rsquo;s a great opportunity to learn how to create powerful interactive CLI applications in Python. Forget about the standard input(), we are going to make it much cooler!\nTo get started, we need to interact with ChatGPT via API, so we need an API Key (OPENAI_API_KEY). You can read more about how to get access to the ChatGPT API in the official documentation. We also need two external Python libraries: Python Prompt Toolkit 3.0 and OpenAI Python Library. Install them in your environment to make sure all the examples below work for you.\nv1. openai api Let\u0026rsquo;s start with a very simple and naive version of our CLI application:\nimport os from openai import OpenAI # pip install \u0026#34;openai\u0026gt;=1.7.0\u0026#34; # Please remember to export your API key to environment variables. # $\u0026gt; export OPENAI_API_KEY=... client = OpenAI(api_key=os.getenv(\u0026#39;OPENAI_API_KEY\u0026#39;)) openai_model = \u0026#39;gpt-3.5-turbo\u0026#39; messages = [ # system message first, it helps set the behavior of the assistant {\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;You are a helpful assistant.\u0026#39;}, ] while True: message = input(\u0026#39;Human: \u0026#39;) if message: messages.append({\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: message}) # https://platform.openai.com/docs/guides/chat/chat-vs-completions chat_completion = client.chat.completions.create( model=openai_model, messages=messages, # Temperature: 0.5 to 0.7 for a balance # between creativity and coherence. temperature=.5, ) content = chat_completion.choices[0].message.content print(f\u0026#39;Robot: {content}\u0026#39;) messages.append({\u0026#39;role\u0026#39;: \u0026#39;assistant\u0026#39;, \u0026#39;content\u0026#39;: content}) This code is straightforward and works! You can run it and communicate with ChatGPT.\nHuman: Hello, how are you doing, robot? Robot: Hello! I\u0026#39;m doing well, thank you for asking. As an AI assistant, I don\u0026#39;t have feelings, but I\u0026#39;m here to help you with any questions or tasks you have. How can I assist you today? However, if you use this script daily, it will soon become annoying. Why? Because it\u0026rsquo;s terribly inconvenient. You can\u0026rsquo;t move the cursor, delete something from the middle of a sentence, you don\u0026rsquo;t have multiline input, no history of your input, no \u0026ldquo;clean\u0026rdquo; exit from the dialog (Ctrl+C leads to an unhandled KeyboardInterrupt exception), etc.\nBut all these issues can be easily fixed with the powerful and popular prompt_toolkit library. Let\u0026rsquo;s gradually improve our first version of the program.\nv2. prompt_toolkit By simply replacing the standard Python input with the prompt from the prompt_toolkit library, we gain the ability to move the cursor and correct something in the middle or at the beginning of a sentence, i.e., edit our prompt in a very familiar manner.\nimport os from openai import OpenAI # pip install \u0026#34;openai\u0026gt;=1.7.0\u0026#34; from prompt_toolkit import prompt client = OpenAI(api_key=os.getenv(\u0026#39;OPENAI_API_KEY\u0026#39;)) openai_model = \u0026#39;gpt-3.5-turbo\u0026#39; messages = [ {\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;You are a helpful assistant.\u0026#39;}, ] while True: message = prompt(\u0026#39;Human: \u0026#39;) # only one change if message: messages.append({\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: message}) chat_completion = client.chat.completions.create( model=openai_model, messages=messages, temperature=.5, ) content = chat_completion.choices[0].message.content print(f\u0026#39;Robot: {content}\u0026#39;) messages.append({\u0026#39;role\u0026#39;: \u0026#39;assistant\u0026#39;, \u0026#39;content\u0026#39;: content}) This is already a good result, but it\u0026rsquo;s just the beginning.\nv3. multiline input The prompt function accepts several dozen different parameters that add various cool features for input in our program. Let\u0026rsquo;s activate some parameters of the prompt function to add a bit of color to our application, change the cursor view, and\u0026hellip; add a multiline input mode!\nSometimes our request to ChatGPT may contain not one, but many lines. Therefore, multiline input will be very convenient. However, keep in mind that the Enter key will now insert a newline instead of accepting and returning the input. The user will now have to press Meta+Enter to accept the input. Or Escape followed by Enter.\nimport os from openai import OpenAI # pip install \u0026#34;openai\u0026gt;=1.7.0\u0026#34; from prompt_toolkit import prompt from prompt_toolkit.cursor_shapes import CursorShape from prompt_toolkit import print_formatted_text, HTML client = OpenAI(api_key=os.getenv(\u0026#39;OPENAI_API_KEY\u0026#39;)) openai_model = \u0026#39;gpt-3.5-turbo\u0026#39; messages = [ {\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;You are a helpful assistant.\u0026#39;}, ] reply_template = \u0026#39;\u0026lt;style fg=\u0026#34;ansiwhite\u0026#34; bg=\u0026#34;ansigreen\u0026#34;\u0026gt; Robot:\u0026lt;/style\u0026gt; %s\u0026#39; def get_prompt(): return [ (\u0026#39;bg:cornsilk fg:maroon\u0026#39;, \u0026#39; Human:\u0026#39;), (\u0026#39;\u0026#39;, \u0026#39; \u0026#39;), ] while True: message = prompt(get_prompt, cursor=CursorShape.BLOCK, multiline=True) if message: messages.append({\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: message}) chat_completion = client.chat.completions.create( model=openai_model, messages=messages, temperature=.5, ) content = chat_completion.choices[0].message.content print_formatted_text(HTML(reply_template % content)) messages.append({\u0026#39;role\u0026#39;: \u0026#39;assistant\u0026#39;, \u0026#39;content\u0026#39;: content}) Let\u0026rsquo;s test the multiline input mode with an example. Let\u0026rsquo;s ask ChatGPT a multiline question:\nHuman: Hello, Robot! Can you fix the code example below? print(\u0026#39;multiline mode\u0026#34;) # it\u0026#39;s Python Robot: Certainly! It looks like there\u0026#39;s a small error in the code. The closing quotation mark for the string is incorrect. Here\u0026#39;s the corrected code: print(\u0026#39;multiline mode\u0026#39;) # it\u0026#39;s Python Now the code should work properly and print \u0026#39;multiline mode\u0026#39;. v4. history We\u0026rsquo;re used to our shell \u0026ldquo;remembering\u0026rdquo; the history of our commands, which can be stored in .bash_history file, for example. Also, our shells can make suggestions, which can be predefined or taken from our command history. We could also use this functionality when communicating with ChatGPT in the terminal. Plus, it\u0026rsquo;s not difficult to enable these features in prompt_toolkit.\nIn the example below, we\u0026rsquo;ll already have a history of our requests to ChatGPT. And this history will be stored between runs of our application in the .prompt_history file.\nBased on this history, suggestions will be formed, which can be activated by pressing the \u0026ldquo;right arrow\u0026rdquo; key (‚û°Ô∏è).\nAnother difference from previous versions: the PromptSession class will be used.\nimport os from openai import OpenAI # pip install \u0026#34;openai\u0026gt;=1.7.0\u0026#34; from prompt_toolkit import PromptSession from prompt_toolkit.history import FileHistory from prompt_toolkit.auto_suggest import AutoSuggestFromHistory from prompt_toolkit.cursor_shapes import CursorShape from prompt_toolkit import print_formatted_text, HTML client = OpenAI(api_key=os.getenv(\u0026#39;OPENAI_API_KEY\u0026#39;)) openai_model = \u0026#39;gpt-3.5-turbo\u0026#39; messages = [ {\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;You are a helpful assistant.\u0026#39;}, ] reply_template = \u0026#39;\u0026lt;style fg=\u0026#34;ansiwhite\u0026#34; bg=\u0026#34;ansigreen\u0026#34;\u0026gt; Robot:\u0026lt;/style\u0026gt; %s\u0026#39; def get_prompt(): return [ (\u0026#39;bg:cornsilk fg:maroon\u0026#39;, \u0026#39; Human:\u0026#39;), (\u0026#39;\u0026#39;, \u0026#39; \u0026#39;), ] prompt_history = FileHistory(\u0026#39;.prompt_history\u0026#39;) session = PromptSession(history=prompt_history) while True: message = session.prompt( get_prompt, cursor=CursorShape.BLOCK, auto_suggest=AutoSuggestFromHistory(), multiline=True, ) if message: messages.append({\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: message}) chat_completion = client.chat.completions.create( model=openai_model, messages=messages, temperature=.5, ) content = chat_completion.choices[0].message.content print_formatted_text(HTML(reply_template % content)) messages.append({\u0026#39;role\u0026#39;: \u0026#39;assistant\u0026#39;, \u0026#39;content\u0026#39;: content}) Test this version of the script: it\u0026rsquo;s not much larger than the first one, but it makes the user\u0026rsquo;s input much more convenient.\nv5. dialog In our program, there\u0026rsquo;s a very important global setting - the ChatGPT model we use (openai_model). It would be convenient to choose a specific ChatGPT model at the time of script launch. Let\u0026rsquo;s implement this feature by adding a full-screen dialog to select the ChatGPT model.\nimport os from openai import OpenAI # pip install \u0026#34;openai\u0026gt;=1.7.0\u0026#34; from prompt_toolkit import PromptSession from prompt_toolkit.history import FileHistory from prompt_toolkit.auto_suggest import AutoSuggestFromHistory from prompt_toolkit.cursor_shapes import CursorShape from prompt_toolkit import print_formatted_text, HTML from prompt_toolkit.shortcuts import radiolist_dialog client = OpenAI(api_key=os.getenv(\u0026#39;OPENAI_API_KEY\u0026#39;)) openai_model = \u0026#39;gpt-3.5-turbo\u0026#39; messages = [ {\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;You are a helpful assistant.\u0026#39;}, ] reply_template = \u0026#39;\u0026lt;style fg=\u0026#34;ansiwhite\u0026#34; bg=\u0026#34;ansigreen\u0026#34;\u0026gt; Robot:\u0026lt;/style\u0026gt; %s\u0026#39; def get_prompt(): return [ (\u0026#39;bg:cornsilk fg:maroon\u0026#39;, \u0026#39; Human:\u0026#39;), (\u0026#39;\u0026#39;, \u0026#39; \u0026#39;), ] prompt_history = FileHistory(\u0026#39;.prompt_history\u0026#39;) session = PromptSession(history=prompt_history) openai_model = radiolist_dialog( title=\u0026#39;Choosing a ChatGPT model\u0026#39;, text=\u0026#39;Which ChatGPT model would you like ?\u0026#39;, values=[ (\u0026#39;gpt-3.5-turbo\u0026#39;, \u0026#39;gpt-3.5-turbo\u0026#39;), (\u0026#39;gpt-3.5-turbo-16k\u0026#39;, \u0026#39;gpt-3.5-turbo-16k\u0026#39;), (\u0026#39;gpt-4\u0026#39;, \u0026#39;gpt-4\u0026#39;), (\u0026#39;gpt-4-1106-preview\u0026#39;, \u0026#39;gpt-4-1106-preview (turbo)\u0026#39;), ] ).run() while openai_model: message = session.prompt( get_prompt, cursor=CursorShape.BLOCK, auto_suggest=AutoSuggestFromHistory(), multiline=True, ) if message: messages.append({\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: message}) chat_completion = client.chat.completions.create( model=openai_model, messages=messages, temperature=.5, ) content = chat_completion.choices[0].message.content print_formatted_text(HTML(reply_template % content)) messages.append({\u0026#39;role\u0026#39;: \u0026#39;assistant\u0026#39;, \u0026#39;content\u0026#39;: content}) Running this version of the script, you\u0026rsquo;ll see something like this:\nv6. graceful stop It\u0026rsquo;s time to add a graceful stop to our program, for example, exit by Ctrl+C. Also, let\u0026rsquo;s rewrite our entire script in an asynchronous style. This version of the script can already be used on a daily basis without any discomfort üòä\nimport asyncio import os from openai import AsyncOpenAI from prompt_toolkit import PromptSession from prompt_toolkit.history import FileHistory from prompt_toolkit.auto_suggest import AutoSuggestFromHistory from prompt_toolkit.cursor_shapes import CursorShape from prompt_toolkit import print_formatted_text, HTML from prompt_toolkit.shortcuts import radiolist_dialog from prompt_toolkit.patch_stdout import patch_stdout aclient = AsyncOpenAI(api_key=os.getenv(\u0026#39;OPENAI_API_KEY\u0026#39;)) def get_prompt(): return [ (\u0026#39;bg:cornsilk fg:maroon\u0026#39;, \u0026#39; Human:\u0026#39;), (\u0026#39;\u0026#39;, \u0026#39; \u0026#39;), ] def choose_openai_model() -\u0026gt; str: return radiolist_dialog( title=\u0026#39;Choosing a ChatGPT model\u0026#39;, text=\u0026#39;Which ChatGPT model would you like ?\u0026#39;, values=[ (\u0026#39;gpt-3.5-turbo\u0026#39;, \u0026#39;gpt-3.5-turbo\u0026#39;), (\u0026#39;gpt-3.5-turbo-16k\u0026#39;, \u0026#39;gpt-3.5-turbo-16k\u0026#39;), (\u0026#39;gpt-4\u0026#39;, \u0026#39;gpt-4\u0026#39;), (\u0026#39;gpt-4-1106-preview\u0026#39;, \u0026#39;gpt-4-1106-preview (turbo)\u0026#39;), ] ).run() async def main(openai_model: str): messages = [ {\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;You are a helpful assistant.\u0026#39;}, ] name = HTML(\u0026#39;\u0026lt;style fg=\u0026#34;ansiwhite\u0026#34; bg=\u0026#34;ansigreen\u0026#34;\u0026gt; Robot:\u0026lt;/style\u0026gt; \u0026#39;) prompt_history = FileHistory(\u0026#39;.prompt_history\u0026#39;) session = PromptSession(history=prompt_history) with patch_stdout(): while True: message = await session.prompt_async( get_prompt, cursor=CursorShape.BLOCK, auto_suggest=AutoSuggestFromHistory(), multiline=True, ) if message: messages.append({\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: message}) print_formatted_text(name) chat_completion = await aclient.chat.completions.create( model=openai_model, messages=messages, temperature=.5, stream=True, # the streaming mode ) reply = \u0026#39;\u0026#39; async for chunk in chat_completion: content = chunk.choices[0].delta.content print_formatted_text(content, end=\u0026#39;\u0026#39;) reply += content or \u0026#39;\u0026#39; print_formatted_text(\u0026#39;\u0026#39;) messages.append({\u0026#39;role\u0026#39;: \u0026#39;assistant\u0026#39;, \u0026#39;content\u0026#39;: reply}) if __name__ == \u0026#39;__main__\u0026#39;: try: model = choose_openai_model() if model: asyncio.run(main(model)) except KeyboardInterrupt: print_formatted_text(\u0026#39;GoodBye!\u0026#39;) Now, running the script, you can press Ctrl+C at any time, and the program execution will be terminated. At the same time, you won\u0026rsquo;t see any unpleasant messages about unhandled exceptions. The program ends correctly.\nMoreover, the streaming mode for receiving a response from ChatGPT has been enabled. In other words, once a part of the response from ChatGPT is received, it is immediately displayed on the screen. In this form, waiting for a response from ChatGPT is a bit more fun, especially in those cases where the response from ChatGPT is really large and takes several seconds to fully form.\nv7. \u0026hellip; You can continue to develop our CLI application further. For this, the prompt_toolkit package has a lot more interesting things. But the examples provided are enough for the article. Explore and use the rest on your own!\n","date":"2023-09-28T00:00:00Z","image":"https://python.study/p/creating-interactive-cli-app-with-chatgpt-in-python/cover_hu02aa61ae1d9de35cbe238d2676170cb9_92491_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/creating-interactive-cli-app-with-chatgpt-in-python/","title":"Creating a Powerful Interactive CLI App with ChatGPT in Python"},{"content":"Any function in Python that contains the keyword yield is called a generator function. When called, a generator function returns a generator object that \u0026ldquo;wraps\u0026rdquo; the body of the function. When an object of the generator is passed to the next() function, execution continues until the next yield statement in the function body, and the value associated with that yield is returned. When the function exits, the generator object raises a StopIteration exception according to the Iterator protocol. Therefore, a generator function can be used wherever an iterator can be used, such as in loops.\nLet\u0026rsquo;s consider an example of a generator function called finder that searches for a specific string in Python source code files (files with the extension *.py). The string can be represented by a regular expression. In addition to the search string, our generator function will also take the path to the directory containing the code.\nThe example code for the finder generator function is shown below. Note that finder uses another generator function called search to determine the line number where a match was found.\nimport glob import os import re def search(filename: str, pattern: re.Pattern): with open(filename) as fd: for num, line in enumerate(fd.readlines(), 1): if pattern.search(line): yield num # line number in the file where a match was found def finder(pattern: str, src_dir: str): it = glob.iglob(\u0026#39;**/*.py\u0026#39;, root_dir=src_dir, recursive=True) _pattern = re.compile(pattern) for path in it: path = os.path.join(src_dir, path) for line_num in search(path, _pattern): yield path, line_num gen_obj = finder(\u0026#39;import re\u0026#39;, \u0026#39;.\u0026#39;) print(next(gen_obj)) # (\u0026#39;./example.py\u0026#39;, 3) print(next(gen_obj)) # (\u0026#39;./example.py\u0026#39;, 23) # Generator is an iterator from collections.abc import Iterator print(isinstance(gen_obj, Iterator)) # True # ...which means that a generator function can be used in a loop for r in finder(\u0026#39;import re\u0026#39;, \u0026#39;.\u0026#39;): print(f\u0026#39;file {r[0]}, line {r[1]}\u0026#39;) # Output in the loop: # file ./example.py, line 3 # file ./example.py, line 23 # and so on... In this example, we will explore some subtle aspects of using generator functions.\nreturn In the example, the return from the generator function happens implicitly (there is no explicit return statement). The question arises: what if there is an explicit return statement that returns a value? How can the calling code access this returned value?\nIt turns out that the returned value will be passed to the value field of the StopIteration exception! Let\u0026rsquo;s modify our generator function code to return the total number of matches found and print it.\nimport glob import os import re def search(filename: str, pattern: re.Pattern): with open(filename) as fd: for num, line in enumerate(fd.readlines(), 1): if pattern.search(line): yield num # line number in the file where a match was found def finder(pattern: str, src_dir: str): it = glob.iglob(\u0026#39;**/*.py\u0026#39;, root_dir=src_dir, recursive=True) _pattern = re.compile(pattern) total = 0 for path in it: path = os.path.join(src_dir, path) for line_num in search(path, _pattern): yield path, line_num total += 1 # explicit return statement in the function return total # total number of matches found gen_obj = finder(\u0026#39;import re\u0026#39;, \u0026#39;.\u0026#39;) try: while True: print(next(gen_obj)) except StopIteration as ctx: # the returned value is stored in the value field of # the StopIteration exception print(ctx.value) # total number of matches found Doing the same thing in a for loop is not possible because the StopIteration exception will be implicitly caught and handled. In other words, we won\u0026rsquo;t have access to it.\nIn fact, an explicit return statement with a value is very rare in generator functions and is mostly used for debugging purposes.\nyield from Let\u0026rsquo;s pay attention to the yield statement in the code of the generator function finder - it is located inside a loop. The call to the generator function search returns a generator object, which is essentially an iterator that we iterate over in this loop. In our case, we need to get everything that this iterator yields. To achieve this, we don\u0026rsquo;t need the loop at all; it is enough to use the yield from statement. Let\u0026rsquo;s rewrite the code of the generator function finder by adding yield from and removing the explicit loop over the iterator.\nimport glob import os import re from itertools import repeat def search(filename: str, pattern: re.Pattern): with open(filename) as fd: for num, line in enumerate(fd.readlines(), 1): if pattern.search(line): yield num # line number in the file where a match was found def finder(pattern: str, src_dir: str): it = glob.iglob(\u0026#39;**/*.py\u0026#39;, root_dir=src_dir, recursive=True) _pattern = re.compile(pattern) for path in it: path = os.path.join(src_dir, path) yield from zip(repeat(path), search(path, _pattern)) gen_obj = finder(\u0026#39;import re\u0026#39;, \u0026#39;.\u0026#39;) print(next(gen_obj)) # (\u0026#39;./example.py\u0026#39;, 3) print(next(gen_obj)) # (\u0026#39;./example.py\u0026#39;, 5) The expression zip(repeat(path), search(path, _pattern)) may look cumbersome, but that\u0026rsquo;s because our generator yields a tuple value - the file path and the line number where a match was found. While the search generator yields line numbers, the path remains the same. We can easily get a sequence of identical paths using the repeat iterator from the itertools module. The zip function is used to yield tuples of values. With the help of the itertools module and functions like zip, Python allows us to write code in a functional style.\nHowever, it is important to keep the code understandable for others. We could have shortened the finder generator function to just one line (ü§Ø), but it would have been extremely difficult to understand. Here\u0026rsquo;s an example:\nimport glob import os import re from itertools import repeat, chain def search(filename: str, pattern: re.Pattern): with open(filename) as fd: for num, line in enumerate(fd.readlines(), 1): if pattern.search(line): yield num # line number in the file where a match was found def finder(pattern: str, src_dir: str): yield from chain.from_iterable( zip(repeat(path), search(path, re.compile(pattern))) for path in ( os.path.join(src_dir, path) for path in glob.iglob(\u0026#39;**/*.py\u0026#39;, root_dir=src_dir, recursive=True) ) ) # better not to write like this! gen_obj = finder(\u0026#39;import re\u0026#39;, \u0026#39;.\u0026#39;) print(next(gen_obj)) # (\u0026#39;./example.py\u0026#39;, 3) print(next(gen_obj)) # (\u0026#39;./example.py\u0026#39;, 5) decorator Applying a decorator to a generator function gives an unexpected result. The decorator does not wrap the body of the generator function. The decorator is executed when the generator function is called, and at this stage, only the generator object is created. Therefore, for example, if we try to measure the execution time of a generator function, we will only get the time it takes to create the generator itself. The simple example below demonstrates this:\nimport time def timeit(func): def wrapper(*args, **kwargs): t = time.perf_counter() result = func(*args, **kwargs) elapsed = time.perf_counter() - t print(f\u0026#39;elapsed {elapsed:0.8f}s\u0026#39;) return result return wrapper @timeit def simple_func(): time.sleep(1) simple_func() # output something like \u0026#34;elapsed 1.00515067s\u0026#34; @timeit def gen_func(): time.sleep(1) yield 1 list(gen_func()) # output something like \u0026#34;elapsed 0.00001092s\u0026#34; In this example, the timeit decorator, which wraps the generator function gen_func, is not very useful. However, it is possible to write a decorator for a generator function. For example, we can rewrite timeit like this:\nimport time def timeit(func): def wrapper(*args, **kwargs): t = time.perf_counter() yield from func(*args, **kwargs) elapsed = time.perf_counter() - t print(f\u0026#39;elapsed {elapsed:0.8f}s\u0026#39;) return wrapper @timeit def gen_func(): time.sleep(1) yield 1 time.sleep(1) yield 2 list(gen_func()) # output something like \u0026#34;elapsed 2.00686138s\u0026#34; async generator A generator function can be asynchronous, in which case it will create asynchronous generators (async_generator). To work with asynchronous generators in Python, there is the async for construct. Let\u0026rsquo;s rewrite our generator function finder in an asynchronous form, using async for to work with the generator.\nimport asyncio import glob import os import re async def search(filename: str, pattern: re.Pattern): with open(filename) as fd: for num, line in enumerate(fd.readlines(), 1): if pattern.search(line): yield num # line number in the file where a match was found async def finder(pattern: str, src_dir: str): it = glob.iglob(\u0026#39;**/*.py\u0026#39;, root_dir=src_dir, recursive=True) _pattern = re.compile(pattern) for path in it: path = os.path.join(src_dir, path) async for line_num in search(path, _pattern): yield path, line_num async def main(): async for r in finder(\u0026#39;import re\u0026#39;, \u0026#39;.\u0026#39;): print(f\u0026#39;file {r[0]}, line {r[1]}\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: asyncio.run(main()) It was not difficult to rewrite the generator function as an asynchronous one.\ncoroutines In PEP 342 \u0026ldquo;Coroutines via Enhanced Generators\u0026rdquo; it is stated that generators can be used as coroutines. For this purpose, generators have special methods such as .send() and .throw(), and the yield statement not only yields values but also consumes them. When you see such usage of a generator function, know that it is a coroutine. And a coroutine is not an iterator! Coroutines have nothing to do with iteration.\nMoreover, with the advent of asyncio, the use of generators as coroutines becomes almost obsolete. Nevertheless, it is important to be able to recognize a \u0026ldquo;classic\u0026rdquo; coroutine in the code to understand that it is not about iteration. Let\u0026rsquo;s provide an example of such a coroutine:\ndef adder(): acc = 0 while True: x = yield acc acc += x coro_add = adder() next(coro_add) print(coro_add.send(1)) # 1 (0 + 1) print(coro_add.send(2)) # 3 (1 + 2) print(coro_add.send(3)) # 6 (3 + 3) print(coro_add.send(4)) # 10 (6 + 4) Pay attention to the yield statement. In this case, yield not only yields the value of acc but also accepts a value that is passed through the send method call. Coroutines consume data, while iterators produce data. Even though both cases use the yield keyword, they are two completely different uses of generator functions.\nThat\u0026rsquo;s all for now.\nAdditional information about generator functions and generators can be found in the following documents:\nPEP 255 ‚Äì Simple Generators PEP 342 ‚Äì Coroutines via Enhanced Generators PEP 380 ‚Äì Syntax for Delegating to a Subgenerator PEP 479 ‚Äì Change StopIteration handling inside generators ","date":"2023-09-04T00:00:00Z","image":"https://python.study/p/subtle-aspects-of-pythons-generator-function/cover_hu5af12b01eb0664f374c4a5aeb2956b3a_132976_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/subtle-aspects-of-pythons-generator-function/","title":"Subtle Aspects of Python's Generator Function"},{"content":"Python\u0026rsquo;s __slots__ is a simple yet powerful feature that is often overlooked and misunderstood by many. By default, Python stores instance attributes in a dictionary called __dict__ that belongs to the instance itself. This common approach is associated with significant overhead. However, this behavior can be altered by defining a class attribute called __slots__.\nWhen __slots__ is defined, Python uses an alternative storage model for instance attributes: the attributes are stored in a hidden array of references, which consumes significantly less memory than a dictionary. The __slots__ attribute itself is a sequence of the instance attribute names. It must be present at the time of class declaration; adding or modifying it later has no effect.\nAttributes listed in __slots__ behave just as if they were listed in __dict__ - there\u0026rsquo;s no difference. However, __dict__ is no longer used and attempting to access it will result in an error:\nimport datetime class Book: __slots__ = (\u0026#39;title\u0026#39;, \u0026#39;author\u0026#39;, \u0026#39;isbn\u0026#39;, \u0026#39;pub_date\u0026#39;, \u0026#39;rating\u0026#39;) book = Book() book.title = \u0026#39;Learning Python\u0026#39; book.author = \u0026#39;Mark Lutz\u0026#39; book.pub_date = datetime.date(2013, 7, 30) book.rating = 4.98 print(book.title) # Learning Python print(book.rating) # 4.98 # This will raise AttributeError: \u0026#39;Book\u0026#39; object has no attribute \u0026#39;__dict__\u0026#39; print(book.__dict__) So, what are the benefits of using __slots__ over the traditional __dict__? There are three main aspects:\nI. Faster access to instance attributes This might be hard to notice in practice, but it is indeed the case.\nII. Memory savings This is probably the main argument for using __slots__. We save memory because we are not storing instance attributes in a hash table (__dict__), thus avoiding the additional overhead associated with using a hash table. This can be easily verified in practice using the Pympler library:\nfrom pympler import asizeof class Point: def __init__(self, x: float, y: float): self.x = x self.y = y class SlotPoint: __slots__ = (\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;) def __init__(self, x: float, y: float): self.x = x self.y = y p = [Point(n, n+1) for n in range(1000)] print(f\u0026#39;Point: {asizeof.asizeof(p)} bytes\u0026#39;) # Point: 216768 bytes p = [SlotPoint(n, n+1) for n in range(1000)] print(f\u0026#39;SlotPoint: {asizeof.asizeof(p)} bytes\u0026#39;) # SlotPoint: 112656 bytes In our example, the memory savings were almost twofold. However, the savings will not be as significant if the object has more attributes or if their types are complex. The savings might only amount to a few percent.\nIII. More secure access to instance attributes __dict__ allows us to define new attributes on the fly and use them. __slots__ restricts us to what is listed in it:\nclass Book: pass class SlotBook: __slots__ = () book = Book() book.title = \u0026#39;Learning Python\u0026#39; # no error, a new attribute is created print(book.title) # Learning Python book = SlotBook() # This will raise AttributeError: \u0026#39;SlotBook\u0026#39; object has no attribute \u0026#39;title\u0026#39; book.title = \u0026#39;Learning Python\u0026#39; Whether to use __slots__ or not depends on the specific case. It might be beneficial in some cases and problematic in others, especially in more complex scenarios, like when inheriting from a class that has defined __slots__. In this case, the interpreter ignores the inherited __slots__ attribute, and __dict__ reappears in the subclass:\nclass SlotBook: __slots__ = () class Book(SlotBook): pass book = Book() book.title = \u0026#39;Learning Python\u0026#39; # no error, a new attribute is created print(book.title) # Learning Python But don\u0026rsquo;t be afraid or forget about __slots__. Use it in simple cases where there is no inheritance, few attributes, and the attributes are simple types, like numbers, especially when the number of your instances is in the hundreds of thousands or millions. At the very least, you\u0026rsquo;ll get a noticeable memory saving.\nFor more detailed information about __slots__, you can refer to this great article: Using Slots.\n","date":"2023-07-31T00:00:00Z","image":"https://python.study/p/dont-forget-about-slots-in-python/cover_hu5b35917caba5432d05c4f15a017abf8a_108547_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/dont-forget-about-slots-in-python/","title":"Don't forget about __slots__ in Python!"},{"content":"Python\u0026rsquo;s Abstract Base Classes (ABCs) in the collections.abc module are a set of tools that help us check if a class follows a specific interface. This is done using the issubclass() or isinstance() functions. The interesting part is that the class we\u0026rsquo;re checking doesn\u0026rsquo;t need to inherit from the abstract base type. It just needs to provide the necessary methods to match the abstract type.\nHere\u0026rsquo;s an example:\nfrom collections.abc import Iterable class MyClass: def __iter__(self): ... def __next__(self): ... issubclass(MyClass, Iterable) # Returns True, even though MyClass doesn\u0026#39;t inherit from Iterable! isinstance(MyClass(), Iterable) # Also True, MyClass doesn\u0026#39;t inherit from Iterable, # but provides the necessary methods. ABCs are especially useful in a dynamically-typed language like Python, where you often need to inspect an object to determine what it is and what it can do.\nNow, let\u0026rsquo;s use ABCs to explore the properties of standard Python collections. We\u0026rsquo;ll write a program that builds a table showing which collections support which operations. We\u0026rsquo;ll use the popular package rich to build the table. This package is great for formatted output in the terminal.\nWe\u0026rsquo;ll categorize collections into three types: sequences, mappings, and sets:\nSequences (like lists and tuples) support indexing and slicing, so we\u0026rsquo;ll denote them as x[0:]. Mappings (like dict) associate values with keys, so we\u0026rsquo;ll denote them as x[\u0026quot;key\u0026quot;]. Sets support operations like intersection and difference, so we\u0026rsquo;ll denote them as x \u0026amp; y. We\u0026rsquo;ll also check whether each collection is mutable and whether it\u0026rsquo;s hashable (i.e., can be used as a dictionary key).\nAll this will be determined by a small function written using collections.abc. Here\u0026rsquo;s the code:\nfrom collections import abc def goose_typing(c: abc.Collection) -\u0026gt; list: # The cells of the table will be marked with \u0026#39;x\u0026#39; if the test passed _ = lambda x: \u0026#39;x\u0026#39; if x is True else \u0026#39;\u0026#39; mutable = (abc.MutableSequence, abc.MutableMapping, abc.MutableSet) r = [ c.__name__, _(issubclass(c, abc.Sequence)), _(issubclass(c, abc.Mapping)), _(issubclass(c, abc.Set)), _(issubclass(c, mutable)), _(issubclass(c, abc.Hashable)), ] return r The function name, goose_typing, is not a mistake. This approach is indeed called Goose Typing, not Duck Typing.\nNow we just need to build the table using the rich package. Here\u0026rsquo;s the code:\nfrom rich.console import Console from rich.table import Table table = Table(title=\u0026#39;Python Collections\u0026#39;) table.add_column(\u0026#39;\u0026#39;, justify=\u0026#39;right\u0026#39;, style=\u0026#39;cyan\u0026#39;, no_wrap=True) table.add_column(\u0026#39;x[0:]\u0026#39;, justify=\u0026#39;center\u0026#39;) table.add_column(\u0026#39;x[\u0026#34;key\u0026#34;]\u0026#39;, justify=\u0026#39;center\u0026#39;) table.add_column(\u0026#39;x \u0026amp; y\u0026#39;, justify=\u0026#39;center\u0026#39;) table.add_column(\u0026#39;mutable\u0026#39;, justify=\u0026#39;center\u0026#39;) table.add_column(\u0026#39;hashable\u0026#39;, justify=\u0026#39;center\u0026#39;) from array import array # We\u0026#39;ll also investigate the array class for c in (array, list, tuple, dict, set, frozenset): table.add_row(*goose_typing(c)) console = Console() console.print(table) Running this script will give you a beautiful table showing the properties of standard Python collections.\nPython Collections ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì ‚îÉ ‚îÉ x[0:] ‚îÉ x[\u0026#34;key\u0026#34;] ‚îÉ x \u0026amp; y ‚îÉ mutable ‚îÉ hashable ‚îÉ ‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î© ‚îÇ array ‚îÇ x ‚îÇ ‚îÇ ‚îÇ x ‚îÇ ‚îÇ ‚îÇ list ‚îÇ x ‚îÇ ‚îÇ ‚îÇ x ‚îÇ ‚îÇ ‚îÇ tuple ‚îÇ x ‚îÇ ‚îÇ ‚îÇ ‚îÇ x ‚îÇ ‚îÇ dict ‚îÇ ‚îÇ x ‚îÇ ‚îÇ x ‚îÇ ‚îÇ ‚îÇ set ‚îÇ ‚îÇ ‚îÇ x ‚îÇ x ‚îÇ ‚îÇ ‚îÇ frozenset ‚îÇ ‚îÇ ‚îÇ x ‚îÇ ‚îÇ x ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò Using Goose Typing, you can check whether an unknown object you\u0026rsquo;ve received matches a certain interface, and then decide how to work with it.\nLet\u0026rsquo;s try to investigate something more interesting than list or dict. For example, this:\n# ... right after the loop d = dict() table.add_row(*goose_typing(d.keys().__class__)) # dict_keys The result:\nPython Collections ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì ‚îÉ ‚îÉ x[0:] ‚îÉ x[\u0026#34;key\u0026#34;] ‚îÉ x \u0026amp; y ‚îÉ mutable ‚îÉ hashable ‚îÉ ‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î© ‚îÇ array ‚îÇ x ‚îÇ ‚îÇ ‚îÇ x ‚îÇ ‚îÇ ‚îÇ list ‚îÇ x ‚îÇ ‚îÇ ‚îÇ x ‚îÇ ‚îÇ ‚îÇ tuple ‚îÇ x ‚îÇ ‚îÇ ‚îÇ ‚îÇ x ‚îÇ ‚îÇ dict ‚îÇ ‚îÇ x ‚îÇ ‚îÇ x ‚îÇ ‚îÇ ‚îÇ set ‚îÇ ‚îÇ ‚îÇ x ‚îÇ x ‚îÇ ‚îÇ ‚îÇ frozenset ‚îÇ ‚îÇ ‚îÇ x ‚îÇ ‚îÇ x ‚îÇ ‚îÇ dict_keys ‚îÇ ‚îÇ ‚îÇ x ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò The result is interesting. The dict_keys object, returned by calling keys() on a dictionary, behaves like a set, but is neither mutable nor hashable. This means you can find common keys between two dictionaries like this:\nd1 = {\u0026#39;1\u0026#39;: 1, \u0026#39;2\u0026#39;: 2} d2 = {\u0026#39;1\u0026#39;: 1, \u0026#39;3\u0026#39;: 3} print(d1.keys() \u0026amp; d2.keys()) # sets intersection # Outputs the common keys between two dictionaries: {\u0026#39;1\u0026#39;} ABCs and Goose Typing can help you to write more type-safe code in Python.\nYou can read about Goose Typing in the wonderful book Fluent Python, by Luciano Ramalho. For more information on ABCs, check out the official Python documentation.\nFor more on the rich package, see the docs.\n","date":"2023-07-12T00:00:00Z","image":"https://python.study/p/exploring-python-collections-with-abc-goose-typing/cover_huf1b3e8f1fc062b75bd01d9b76206c9bc_52365_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/exploring-python-collections-with-abc-goose-typing/","title":"Exploring Python Collections with ABC and Goose Typing"},{"content":"To begin, let\u0026rsquo;s look at an example of downloading a large file using the requests package. The requests package is one of the most popular packages in Python, with millions of downloads every day. You can verify this on the website that publishes statistics on the most downloaded PyPI packages.\nTo run the example, you need to install the requests package. Here is the code:\nimport requests def download(url: str, filename: str): with open(filename, \u0026#39;wb\u0026#39;) as f: with requests.get(url, stream=True) as r: r.raise_for_status() for chunk in r.iter_content(chunk_size=8192): f.write(chunk) download(\u0026#39;https://speed.hetzner.de/100MB.bin\u0026#39;, \u0026#39;100MB.bin\u0026#39;) By setting stream=True in the request, we avoid reading the entire content into memory for large responses. The chunk_size parameter determines the number of bytes to read into memory at a time.\nIf you execute this code, you will notice that it appears to freeze in the terminal while downloading the large file. Let\u0026rsquo;s fix that!\nTo do this, we will install the tqdm package. tqdm is a powerful package for creating fast, customizable progress bars in Python. It can be used in scripts or on the command line.\nLet\u0026rsquo;s rewrite our example using tqdm:\nimport requests import tqdm def download(url: str, filename: str): with open(filename, \u0026#39;wb\u0026#39;) as f: with requests.get(url, stream=True) as r: r.raise_for_status() total = int(r.headers.get(\u0026#39;content-length\u0026#39;, 0)) # tqdm has many interesting parameters. Feel free to experiment! tqdm_params = { \u0026#39;desc\u0026#39;: url, \u0026#39;total\u0026#39;: total, \u0026#39;miniters\u0026#39;: 1, \u0026#39;unit\u0026#39;: \u0026#39;B\u0026#39;, \u0026#39;unit_scale\u0026#39;: True, \u0026#39;unit_divisor\u0026#39;: 1024, } with tqdm.tqdm(**tqdm_params) as pb: for chunk in r.iter_content(chunk_size=8192): pb.update(len(chunk)) f.write(chunk) download(\u0026#39;https://speed.hetzner.de/100MB.bin\u0026#39;, \u0026#39;100MB.bin\u0026#39;) Now, in the terminal, you will see a progress bar indicating the download progress:\nhttps://speed.hetzner.de/100MB.bin: 5%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 5.47M/105M [00:03\u0026lt;01:01, 1.61MB/s] You can customize the progress bar using the parameters provided by tqdm.\ntqdm can be used not only for network-related tasks but also in many other cases. Here is a simple example from the documentation:\nimport tqdm for i in tqdm.tqdm(range(int(100e6))): pass # 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 55815969/100000000 [00:05\u0026lt;00:03, 11312880.86it/s] In conclusion, let\u0026rsquo;s rewrite our example using an asynchronous approach with asyncio. Instead of requests, we will use the httpx package, which provides an API similar to requests but with additional asynchronous methods.\nHere is the code:\nimport asyncio import httpx from tqdm import tqdm async def download(url: str, filename: str): with open(filename, \u0026#39;wb\u0026#39;) as f: async with httpx.AsyncClient() as client: async with client.stream(\u0026#39;GET\u0026#39;, url) as r: r.raise_for_status() total = int(r.headers.get(\u0026#39;content-length\u0026#39;, 0)) tqdm_params = { \u0026#39;desc\u0026#39;: url, \u0026#39;total\u0026#39;: total, \u0026#39;miniters\u0026#39;: 1, \u0026#39;unit\u0026#39;: \u0026#39;B\u0026#39;, \u0026#39;unit_scale\u0026#39;: True, \u0026#39;unit_divisor\u0026#39;: 1024, } with tqdm(**tqdm_params) as pb: downloaded = r.num_bytes_downloaded async for chunk in r.aiter_bytes(): pb.update(r.num_bytes_downloaded - downloaded) f.write(chunk) downloaded = r.num_bytes_downloaded async def main(): \u0026#34;\u0026#34;\u0026#34; Downloading three large files simultaneously. Each file has its own progress bar. \u0026#34;\u0026#34;\u0026#34; loop = asyncio.get_running_loop() urls = [ (\u0026#39;https://speed.hetzner.de/100MB.bin\u0026#39;, \u0026#39;100MB.bin\u0026#39;), (\u0026#39;https://speed.hetzner.de/1GB.bin\u0026#39;, \u0026#39;1GB.bin\u0026#39;), (\u0026#39;http://ipv4.download.thinkbroadband.com/50MB.zip\u0026#39;, \u0026#39;50MB.zip\u0026#39;), ] tasks = [loop.create_task(download(url, name)) for url, name in urls] await asyncio.gather(*tasks, return_exceptions=True) asyncio.run(main()) When you run this code, you will see three progress bars in the terminal, each representing the progress of downloading a specific file.\nhttp://ipv4.download.thinkbroadband.com/50MB.zip: 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 10.5M/50.0M [00:20\u0026lt;01:24, 488kB/s] https://speed.hetzner.de/1GB.bin: 1%|‚ñä | 7.77M/0.98G [00:20\u0026lt;43:02, 403kB/s] https://speed.hetzner.de/100MB.bin: 8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 7.75M/100M [00:20\u0026lt;04:00, 402kB/s] The purpose of this article was to introduce the tqdm package and demonstrate its usage with several useful examples. For more information, refer to the official documentation for the requests, httpx, and tqdm packages.\n","date":"2023-07-04T00:00:00Z","image":"https://python.study/p/download-large-file-in-python-with-progress-bar/cover_huf1b3e8f1fc062b75bd01d9b76206c9bc_151357_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/download-large-file-in-python-with-progress-bar/","title":"Download large file in Python with beautiful progress bar"},{"content":"Dataclasses are simple classes that generally only have a set of fields, without additional functionality (methods). Dataclasses are similar to structures in the C language - a composite data type that encapsulates a set of values of different types without hiding them.\nOn the one hand, a data class can be represented in Python as an ordinary class. But this requires the programmer to perform routine actions: defining the __init__, __str__, comparison methods __eq__, etc.\nIn Python, you can create a data class much easier. Let\u0026rsquo;s consider 4 approaches to this: from simple to most powerful.\nApproach 1. Named tuples collections.namedtuple import datetime from collections import namedtuple field_names = \u0026#39;title author isbn pub_date rating\u0026#39; Book = namedtuple(\u0026#39;Book\u0026#39;, field_names, defaults=[4.98]) # Book is a subclass of tuple print(issubclass(Book, tuple)) # output: True book = Book( title=\u0026#39;Learning Python\u0026#39;, author=\u0026#39;Mark Lutz\u0026#39;, isbn=1449355730, pub_date=datetime.date(2013, 7, 30), ) print(book.title) # Learning Python print(book.rating) # 4.98, by default print(type(book)) # \u0026lt;class \u0026#39;__main__.Book\u0026#39;\u0026gt; print(book) # Book(title=\u0026#39;Learning Python\u0026#39;, author=\u0026#39;Mark...) collections.namedtuple is a factory that creates subclasses of tuple, as indicated by issubclass. We can access data fields by name (book.title), and this will be the same for all data classes in the future. In addition to the useful __str__ method, which outputs a good representation of the object, we also get a meaningful __eq__ method.\nApproach 2. Typed named tuples typing.NamedTuple import datetime from typing import NamedTuple class Book(NamedTuple): title: str author: str isbn: int pub_date: datetime.datetime rating: float = 4.98 # Book is a subclass of tuple print(issubclass(Book, tuple)) # output: True book = Book( title=\u0026#39;Learning Python\u0026#39;, author=\u0026#39;Mark Lutz\u0026#39;, isbn=1449355730, pub_date=datetime.date(2013, 7, 30), ) print(book.title) # Learning Python print(book.rating) # 4.98, by default print(type(book)) # \u0026lt;class \u0026#39;__main__.Book\u0026#39;\u0026gt; print(book) # Book(title=\u0026#39;Learning Python\u0026#39;, author=\u0026#39;Mark...) As can be seen from the example, the use of the data class Book has not changed at all. typing.NamedTuple offers the same functionality and additionally type annotations for each field. The class syntax can be used with typing.NamedTuple starting from Python 3.6. This allows you to add your own methods or override existing ones, for example, define your own __str__ method. Book is still a subclass of tuple.\nApproach 3. Decorator @dataclass import datetime from dataclasses import dataclass @dataclass(frozen=True) class Book: title: str author: str isbn: int pub_date: datetime.datetime rating: float = 4.98 # Book is not a subclass of tuple print(issubclass(Book, tuple)) # output: False book = Book( title=\u0026#39;Learning Python\u0026#39;, author=\u0026#39;Mark Lutz\u0026#39;, isbn=1449355730, pub_date=datetime.date(2013, 7, 30), ) print(book.title) # Learning Python print(book.rating) # 4.98, by default print(type(book)) # \u0026lt;class \u0026#39;__main__.Book\u0026#39;\u0026gt; print(book) # Book(title=\u0026#39;Learning Python\u0026#39;, author=\u0026#39;Mark...) Again, the use of the data class Book has not changed. The class syntax is used, and you can define your own methods. But there is a significant difference from the previous examples: the @dataclass decorator does not rely on inheritance from tuple. And this is rather good! In addition, the @dataclass decorator takes several parameters, such as frozen, which configure the operation of the data class. You can read about them in the documentation. The @dataclass decorator can be used starting from Python 3.7. The dataclasses module was first described in PEP 557.\nApproach 4. External package attrs import datetime from attrs import define @define class Book: title: str author: str isbn: int pub_date: datetime.datetime rating: float = 4.98 # Book is not a subclass of tuple print(issubclass(Book, tuple)) # output: False book = Book( title=\u0026#39;Learning Python\u0026#39;, author=\u0026#39;Mark Lutz\u0026#39;, isbn=1449355730, pub_date=datetime.date(2013, 7, 30), ) print(book.title) # Learning Python print(book.rating) # 4.98, by default print(type(book)) # \u0026lt;class \u0026#39;__main__.Book\u0026#39;\u0026gt; print(book) # Book(title=\u0026#39;Learning Python\u0026#39;, author=\u0026#39;Mark...) The attrs package is external and is not included in the standard Python distribution. It must be installed separately. At first glance, there are no differences from @dataclass at all. Then why use an external package? Here\u0026rsquo;s how the attrs package developers answer this question.\nWhich approach to choose depends on the situation and preferences. Perhaps named tuples will be more than enough for you. But knowing about each of the approaches is useful in any case.\n","date":"2023-06-21T00:00:00Z","image":"https://python.study/p/dataclasses-in-python/cover_huf1b3e8f1fc062b75bd01d9b76206c9bc_142920_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/dataclasses-in-python/","title":"Dataclasses in Python"},{"content":"Python 3.9 introduced two new string methods, removeprefix() and removesuffix(), for various string objects. These methods remove a prefix or suffix (respectively) from a string, if present. The reason for adding these two new methods is that the existing methods, str.lstrip and str.rstrip, often confuse users. These methods remove leading or trailing characters, not substrings. This can lead to unintended removal of useful data.\nFor example, consider the following code:\ns = \u0026#39;__trash__ the most useful content\u0026#39; s = s.lstrip(\u0026#39;__trash__ \u0026#39;) print(s) # output: \u0026#39;e most useful content\u0026#39; In this case, not only was the prefix __trash__ removed, but also part of the useful data (th). This is because lstrip removes all characters in the given set from the beginning of the string.\nTo avoid this, users had to write their own functions or use regular expressions, which can be difficult to read and may contain subtle mistakes. The new methods removeprefix() and removesuffix() do exactly what their names suggest, making them more intuitive and easier to use.\nLet\u0026rsquo;s rewrite the previous code snippet using the removeprefix() method:\ns = \u0026#39;__trash__ the most useful content\u0026#39; s = s.removeprefix(\u0026#39;__trash__ \u0026#39;) print(s) # output: \u0026#39;the most useful content\u0026#39; In this case, only the prefix __trash__ was removed, leaving the useful data intact.\nIf the prefix is not found, the original string is returned.\ns = \u0026#39;__trash__ the most useful content\u0026#39; s = s.removeprefix(\u0026#39;__trash \u0026#39;) # the prefix is not found print(s) # original string: \u0026#39;__trash__ the most useful content\u0026#39; It\u0026rsquo;s worth noting that these new methods are available not only for str, but also for binary bytes and bytearray objects, and collections.UserString.\nFor more information, refer to the documentation for str or PEP 616.\n","date":"2023-05-31T00:00:00Z","image":"https://python.study/p/string-methods-to-remove-prefixes-suffixes/cover_huf4db1f5704ad3c55b9270b5c12f12db6_37127_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/string-methods-to-remove-prefixes-suffixes/","title":"String methods to remove prefixes and suffixes"},{"content":"Starting from Python 3.10, you can use Union type expression in some scenarios.\nThe built-in functions isinstance() and issubclass() take a type or tuple of types as their second argument. Using tuples requires writing additional parentheses.\nConsider the code below:\nx = 42 print(isinstance(x, (int, str))) # output: True print(issubclass(type(x), (int, str))) # output: True Let\u0026rsquo;s rewrite this example using Union type expression:\nx = 42 print(isinstance(x, int | str)) # output: True print(issubclass(type(x), int | str)) # output: True This example is equivalent to the previous one, but it looks cleaner. Instead of (X, Y), we write X | Y using the | (bitwise or) operator.\nUnion type expression is particularly expressive when used in type annotations. Compare the example below without using Union type expression:\nfrom typing import List, Union, Optional def f(lst: List[Union[int, str]], param: Optional[int]) -\u0026gt; Union[float, str]: return \u0026#39;\u0026#39; f([1, \u0026#39;abc\u0026#39;], None) And the same example using Union type expression:\ndef f(lst: list[int | str], param: int | None) -\u0026gt; float | str: return \u0026#39;\u0026#39; f([1, \u0026#39;abc\u0026#39;], None) We didn\u0026rsquo;t even need to import anything from the typing module!\nFor more information about Union type expression, refer to PEP 604.\n","date":"2023-05-29T00:00:00Z","image":"https://python.study/p/union-type-expr-in-python/cover_hu4854bfa0662e3b9660d27bbea9d41d5a_32710_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/union-type-expr-in-python/","title":"Union Type Expression"},{"content":"Function overloading is a mechanism in C++ that allows defining functions with the same name but different parameter sets. The compiler chooses the appropriate function based on the parameters. Each function can be adapted to work with specific parameter types.\nHere\u0026rsquo;s an example of declaring overloaded functions in C++:\n// Prototype three write functions. int write(std::string s); // Write a string. int write(double d); // Write a double. int write(double d, int p); // Write a double with a given precision. However, Python does not have a function overloading mechanism, even if we use type annotations. The following code is incorrect:\ndef func(arg: float): pass # Warning: this function will simply hide the previous one, as they have the same name! def func(arg: list): pass But using the functools.singledispatch decorator, we can achieve behavior similar to function overloading. In other words, we can write specialized versions of a function that perform the same logical operation differently depending on the type of the first argument. When the implementation is chosen based on the type of a single argument, this is known as single dispatch.\nHere\u0026rsquo;s an example of how it looks in code:\nfrom functools import singledispatch @singledispatch def write(arg, other_arg=True): print(f\u0026#39;generic version: {arg!r}\u0026#39;) @write.register def _(arg: float): print(f\u0026#39;specialization for float: {arg:.3}\u0026#39;) @write.register def _(arg: list): print(f\u0026#39;specialization for list: {arg!r}\u0026#39;) write(355 / 113) # output: specialization for float: 3.14 write([\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;]) # output: specialization for list: [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] write(True) # output: generic version: True You can also add overloaded implementations to the function by passing the type directly to the register() decorator.\n# type annotations are replaced with explicit type passing @write.register(bool) def _(arg): print(f\u0026#39;specialization for bool: {arg!r}\u0026#39;) write(True) # output: specialization for bool: True If there is no registered implementation for a specific type, its method resolution order is used to find a more generic implementation. The original function decorated with singledispatch is registered for the base object type, which means it is used if no better implementation is found.\nWithout singledispatch, you would need to write if-else blocks inside the function to handle different types of arguments. This approach is brittle and closed to extension. It is difficult to maintain and extend because you need to modify the function every time you want to add support for a new type of argument. In contrast, singledispatch allows you to write specialized implementations without changing the original code.\nThe singledispatch decorator exists starting from Python 3.4, but supports type annotations only starting from Python 3.7. For more information, see PEP 443 (Single-dispatch generic functions) and official docs.\n","date":"2023-05-24T00:00:00Z","image":"https://python.study/p/function-overloading-in-python/cover_hu5af12b01eb0664f374c4a5aeb2956b3a_123711_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/function-overloading-in-python/","title":"Function Overloading in Python"},{"content":"In Python, function parameters can be Positional-Only, Positional-or-Keyword, or Keyword-Only. Let\u0026rsquo;s consider all three cases in the example function f:\ndef f(pos1, pos2, /, pos_or_kwd1, pos_or_kwd2=None, *, kwd1, kwd2): \u0026#34;\u0026#34;\u0026#34; pos1, pos2 - are Positional-Only pos_or_kwd1, pos_or_kwd2 - are Positional-or-Keyword kwd1, kwd2 - are Keyword-Only \u0026#34;\u0026#34;\u0026#34; pass The rules for defining these parameters are straightforward:\nEverything before the / symbol is Positional-Only parameters. Everything after the * symbol is Keyword-Only parameters. What\u0026rsquo;s between / and * can be passed as both Positional and Keyword. If there is no / symbol, there are no Positional-Only parameters. If there is no * symbol, there are no Keyword-Only parameters. If / and * are not present, arguments can be passed to a function by position or by keyword. Here are some valid calls to this function:\nf(1, 2, \u0026#39;a\u0026#39;, kwd1=\u0026#39;c\u0026#39;, kwd2=\u0026#39;d\u0026#39;) f(1, 2, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, kwd1=\u0026#39;c\u0026#39;, kwd2=\u0026#39;d\u0026#39;) f(1, 2, \u0026#39;a\u0026#39;, pos_or_kwd2=\u0026#39;b\u0026#39;, kwd1=\u0026#39;c\u0026#39;, kwd2=\u0026#39;d\u0026#39;) f(1, 2, pos_or_kwd1=\u0026#39;a\u0026#39;, kwd1=\u0026#39;c\u0026#39;, kwd2=\u0026#39;d\u0026#39;) Note that the first two arguments are Positional-Only, and we cannot pass them as pos1=1. Meanwhile, the last two arguments are Keyword-Only, and we cannot omit the use of the name when passing the argument value.\nHere are some invalid calls to the function f that will raise an exception:\nf(1, 2, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, kwd2=\u0026#39;d\u0026#39;) # raises... # TypeError: f() takes from 3 to 4 positional arguments but 5 positional arguments (and 1 Keyword-Only argument) were given f(pos1=1, pos2=2, pos_or_kwd1=\u0026#39;a\u0026#39;, kwd1=\u0026#39;c\u0026#39;, kwd2=\u0026#39;d\u0026#39;) # raises... # TypeError: f() got some Positional-Only arguments passed as keyword arguments: \u0026#39;pos1, pos2\u0026#39; The logic around optional values for Positional-Only parameters remains the same as for Positional-or-Keyword parameters. For example:\ndef f(pos1, pos2=2, /, pos_or_kwd1=\u0026#39;a\u0026#39;, *, kwd1, kwd2): pass Once a Positional-Only parameter is specified with a default, the following Positional-Only and Positional-or-Keyword parameters need to have defaults as well.\nAs guidance, use Positional-Only if names do not matter or have no meaning, and there are only a few arguments that will always be passed in the same order. Use Keyword-Only when names have meaning, and the function definition is more understandable by being explicit with names.\nFor more information, refer to PEP 3102 (Keyword-Only Arguments) and PEP 570 (Python Positional-Only Parameters).\n","date":"2023-05-23T00:00:00Z","image":"https://python.study/p/keyword-and-positional-only-params-in-func/cover_hu082dc3ac5eba017b12ca5aaf7304ec12_64348_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/keyword-and-positional-only-params-in-func/","title":"Keyword-Only and Positional-Only Parameters in Function"},{"content":"In Python, there are three variable scopes: global, local, and nonlocal.\nLocal scope Local scope refers to variables inside a function that can only be accessed within that function. Control blocks like if, while, and for do not create a new local scope. Variables inside them belong to the enclosing function.\ndef local_scope(): if True: x = \u0026#39;x\u0026#39; print(f\u0026#39;{x} is local\u0026#39;) # outputs `x is local` print(f\u0026#39;{x} is local\u0026#39;) # raises NameError: name \u0026#39;x\u0026#39; is not defined Global scope Global scope refers to variables declared outside functions that can be accessed throughout the program. Technically, Python does not have program-level scope, only module-level scope. Global variables can be accessed from local scope, but to modify them from local scope, you need to use the global keyword.\nThe following example shows that Python does not consider X a global variable because of the assignment inside the function without the global keyword. The error occurs when print is called, even before the actual assignment.\nX = \u0026#39;X\u0026#39; def global_scope_wrong(): print(f\u0026#39;{X} is global\u0026#39;) X += \u0026#39;Y\u0026#39; global_scope_wrong() # raises UnboundLocalError: local variable \u0026#39;X\u0026#39; referenced before assignment The correct way to assign a global variable inside a function is to use the global keyword.\nX = \u0026#39;X\u0026#39; def global_scope(): global X print(f\u0026#39;{X} is global\u0026#39;) X += \u0026#39;Y\u0026#39; global_scope() # outputs \u0026#39;X is global\u0026#39; global_scope() # outputs \u0026#39;XY is global\u0026#39; Nonlocal scope Nonlocal scope is a special scope that only exists for nested functions. Nested functions are used, for example, to create decorators. Variables declared in the function that creates the decorator will be available inside the created decorator function, even after the local scope of the enclosing function is destroyed. This is called a closure.\ndef outer_func(): # closure x = \u0026#39;x\u0026#39; # local for outer_func, nonlocal for inner_func def inner_func(): print(f\u0026#39;{x} is free\u0026#39;) return inner_func f = outer_func() f() # outputs \u0026#39;x is free\u0026#39; To modify a free variable from nonlocal scope, you need to use the nonlocal keyword, similar to using global.\ndef outer_func(): # closure x = \u0026#39;x\u0026#39; # local for outer_func, nonlocal for inner_func def inner_func(): # raises UnboundLocalError if nonlocal is not added nonlocal x print(f\u0026#39;{x} is free\u0026#39;) x += \u0026#39;y\u0026#39; return inner_func f = outer_func() f() # outputs \u0026#39;x is free\u0026#39; f() # outputs \u0026#39;xy is free\u0026#39; Understanding variable scopes is essential for writing correct Python code.\n","date":"2023-05-21T00:00:00Z","image":"https://python.study/p/variable-scopes-local-global-nonlocal/cover_hu85761fd22dfb7cec2c425b8b673aa619_50241_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/variable-scopes-local-global-nonlocal/","title":"Python Variable Scopes: Understanding Local, Global, and Nonlocal"},{"content":"In Python, decorators are a way to modify the behavior of a function without changing its source code. They are a powerful tool that can add extra functionality to your code.\ndef add_two(func): def wrapper(*args, **kwargs): num = func(*args, **kwargs) return num + 2 return wrapper @add_two def get_num(): return 10 print(get_num()) # The result will be 12 The first example shows how you can use a simple decorator to add extra functionality to a function. However, sometimes you need more flexibility in your code. This is where parameterized decorators come in.\ndef add_x(x): def decorator(func): def wrapper(*args, **kwargs): num = func(*args, **kwargs) return num + x return wrapper return decorator @add_x(5) def get_num(): return 10 print(get_num()) # The result will be 15 Parameterized decorators allow you to pass in an argument to the decorator, which in turn modifies the behavior of the wrapped function. This can be quite hard to understand because they work with several nested layers of functions. It can make it difficult to keep track of which function is being called and what arguments are being passed at each stage, possibly leading to errors and making the code harder to work through.\nTo make things easier, you can implement a parameterized decorator using a class. This can help you write more intuitive and clear code because there are fewer levels of nested functions.\nclass add_x: def __init__(self, x): self.x = x def __call__(self, func): def wrapper(*args, **kwargs): num = func(*args, **kwargs) return num + self.x return wrapper @add_x(5) def get_num(): return 10 print(get_num()) # The result will be 15 If you want to learn more about the correct way to write decorators, a good article to read is Graham Dumpleton\u0026rsquo;s \u0026ldquo;How You Implemented Your Python Decorator is Wrong\u0026rdquo;.\n","date":"2023-05-16T00:00:00Z","image":"https://python.study/p/parameterized-decorators/cover_hu604f6feb6c9fb2617719ef3c68bb5d27_67559_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/parameterized-decorators/","title":"Parameterized Decorators"},{"content":"Let\u0026rsquo;s take a look at the new operators for dict that appeared in Python 3.9 - merge (|) and update (|=) operators.\nThe current ways to merge two dicts have several disadvantages:\ndict.update d1.update(d2) modifies d1 in-place.\ne = d1.copy(); e.update(d2) is not an expression and needs a temporary variable.\n{**d1, **d2} Dict unpacking looks ugly and is not easily discoverable. Few people would be able to guess what it means the first time they see it, or think of it as the \u0026ldquo;obvious way\u0026rdquo; to merge two dicts.\nAs Guido said:\nI‚Äôm sorry for PEP 448, but even if you know about **d in simpler contexts, if you were to ask a typical Python user how to combine two dicts into a new one, I doubt many people would think of {**d1, **d2}. I know I myself had forgotten about it when this thread started!\nd1 | d2 The new operators have the same relationship to the dict.update method as the list concatenate (+) and extend (+=) operators have to list.extend. The | operator creates a new dict, while the |= operator updates an existing dict in place.\nKey conflicts will be resolved by keeping the rightmost value. It\u0026rsquo;s important to note that dict union is not commutative; in general: d | e != e | d.\nTo create a new dict, you can use the merge (|) operator. For example:\nd1 = {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 3} d2 = {\u0026#39;a\u0026#39;: 2, \u0026#39;b\u0026#39;: 4, \u0026#39;c\u0026#39;: 6} d3 = d1 | d2 # {\u0026#39;a\u0026#39;: 2, \u0026#39;b\u0026#39;: 4, \u0026#39;c\u0026#39;: 6} To update an existing dict in place, you can use the update (|=) operator. For example:\nd1 = {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 3} d2 = {\u0026#39;a\u0026#39;: 2, \u0026#39;b\u0026#39;: 4, \u0026#39;c\u0026#39;: 6} d1 |= d2 d1 # {\u0026#39;a\u0026#39;: 2, \u0026#39;b\u0026#39;: 4, \u0026#39;c\u0026#39;: 6} In summary, when you need to merge two dicts, you can use the new merge (|) and update (|=) operators. They are more convenient and easier to use than the current ways. For more information about Union Operators To dict, refer to PEP 584.\n","date":"2023-05-15T00:00:00Z","image":"https://python.study/p/union-operators-to-dict/cover_hu20c85b615ab91918969c74a0ff5b5d75_50894_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/union-operators-to-dict/","title":"Union Operators To dict"},{"content":"Generator Expressions (genexp) in Python allow you to iterate over elements one at a time without creating a full list in memory. This is useful when you only need to iterate over the elements and don\u0026rsquo;t need to store them in memory. By doing so, you can conserve memory and improve performance.\nFor example, let\u0026rsquo;s compare these two code snippets:\nsum([x*x for x in range(100_000_000)]) sum(x*x for x in range(100_000_000)) In the first case, a list is created using list comprehensions PEP 202. The entire list is created in memory, and only then is the sum calculated. This can consume a lot of memory.\nIn the second case, a generator object is created, which yields the elements of the sequence to the sum function one by one. The entire list of a billion values is never created, so this case does not consume unnecessary memory.\nTo improve memory usage and performance, use genexp wherever possible and avoid constructing the entire list unnecessarily. For more information about Generator Expressions, refer to PEP 289.\n","date":"2023-05-14T00:00:00Z","image":"https://python.study/p/generator-expressions/cover_hu300533631d39c99fdd84f3f294231c42_29426_120x120_fill_q75_box_smart1.jpeg","permalink":"https://python.study/p/generator-expressions/","title":"Generator Expressions"}]